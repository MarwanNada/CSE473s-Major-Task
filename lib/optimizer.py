class SGD:
    """
    Stochastic Gradient Descent (SGD) Optimizer.
    
    W = W - learning_rate * gradient
    
    """
    def __init__(self, learning_rate=0.01):
        self.learning_rate = learning_rate

    def step(self):
      
        pass